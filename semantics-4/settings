#!/bin/bash

export POP_CARD=5
export PUSH_CARD=5
export MAX_PUSH=2 #1 2 

export INSERTION_PENALTY=0.10
export SCALE_CONCEPT12=1.0
export SCALE_PUSHPOP=1.0
export TRAIN_EM_ITERS=4

# CUED dialogue act annotation expets only one DA per input sentence, 
# as a results it is benefitial to force the decoder to accept hypotheses only with one output dialogue act
# 0 - off - no hard limit on the number of output dialogue acts during decoding
# 1 - the decoder accepts only one DA on its input
export ONLY_ONE_TOP_ROOT_CONCEPT=1

# Set whether the smootnig is perfomed
# '-n' - no smoothing
# ''   - smoothing
# '-p' - smoothing, no pruning
export WORD_NO_SMOOTHING='-n'
export CONCEPT1_NO_SMOOTHING='-n'


export DATA_REDUCTION=100
export TRAIN_DATA_REDUCTION=100

export TRAIN_ALLOW_EMPTY=0   # 0 - words cannot generate empty stacks
                             # 1 - it is possible to generate empty stacks
export TRAIN_USE_ALL=0       # 0 - separate dataset in proportion to 72:8:20
                             # 1 - use all available data as training data
export TRAIN_USE_EMPTY=0     # 0 - don't use empty dialogue acts
                             # 1 - use dialogue acts with empty semantics for training too
export MAKE_XML=0            # 0 - do not generate 
                             # 1 - generate them
		     

# Possible parse types: LR, LRRL, LRRL-FT
export PARSE_TYPE='LRRL-FT'


# Possible input chains:
#       none, join_acts, join_acts_selected, filler, only_[speech_act]
export INPUT_CHAIN='none'
#export INPUT_CHAIN_DCD=none

# Possible datasets: 
#       word, lemma, pos, 
#       conf_word, conf_lemma, conf_pos, 
#       analytical,
#       domain_speech_act, speech_act, domain,
#       off (symbol is not used)
export S1_DATASET=word
export S2_DATASET=off
export S3_DATASET=off
export ORIG_DATASETS=word,word


export S1_NEGEX=1
export S2_NEGEX=0
export S3_NEGEX=0

export S1_NEG_THRESHOLD=1
export S2_NEG_THRESHOLD=1
export S3_NEG_THRESHOLD=1

export S1_PRUNE_COUNT=1
export S2_PRUNE_COUNT=-0.05
export S3_PRUNE_COUNT=-0.05

export SKIP_DUMMY_PROBS="0.3 0.7"
export JUMP_PROBS="0.5 0.5 0.0 0.0 0.0 0.0 0.0"
export BACKOFF_FA_PROBS="0.9999 0.0001"

export S1_INDEX=0
export S2_INDEX=1
export S3_INDEX=2

export CONFUSE=0

export S1_NEG_METHOD=basic
export S2_NEG_METHOD=basic
export S3_NEG_METHOD=basic

export USE_NAMED_ENTITIES=0       # Use named entites?
export USE_COMMON_DATASET=0       # Use common dataset for lexical initialization?

#export SRESULTS_ONLY=@DA
export SRESULTS_SKIP=@SKIP,@DA

export FSM_STATES=200
export FSM_CUTOFF_SYM='1e-20'
export FSM_CUTOFF_TRANS='1e-10'

